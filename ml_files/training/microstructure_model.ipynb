{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model for M22 and Kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import re\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Input\n",
    "from keras.layers import concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import get_custom_objects\n",
    "from keras.backend import sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set file paths for input and output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where the images and data come from\n",
    "input = os.path.join(\"..\",\"..\",\"data\")\n",
    "# input = os.path.join(\"..\",'data')\n",
    "# input = \"C:\\\\Users\\\\leomo\\\\Documents\\\\Boise\\\\mamivand\\\\data\"\n",
    "image_dir = os.path.join(input, \"spinodal_images\", \"crop_images\")\n",
    "# Where output csv files will go\n",
    "output = \"results\"\n",
    "\n",
    "# Remove the output if it is already there\n",
    "if os.path.exists(output):\n",
    "    shutil.rmtree(output)\n",
    "os.mkdir(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the csv with numerical results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading data...\")\n",
    "# data = pd.read_csv(os.path.join(input,\"results\",\"spinodal_results.csv\"))\n",
    "data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size_ = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the images, and resize and rescale them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images...\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading images...\")\n",
    "# size_ = 64\n",
    "image_paths = os.listdir(image_dir)\n",
    "images = []\n",
    "m22_list = []\n",
    "k_list = []\n",
    "for image_path in image_paths:\n",
    "    total_path = os.path.join(input, \"spinodal_images\", \"crop_images\", image_path)\n",
    "    # image = cv2.imread(total_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.imread(total_path)\n",
    "    \n",
    "    image = np.array(tf.image.rgb_to_grayscale(image))\n",
    "    thresh, imageb = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "    image = cv2.resize(image, (size_,size_))\n",
    "    image = np.array(image, dtype = float)\n",
    "    image = np.expand_dims(image, 2)\n",
    "    image = image / 255.0\n",
    "    images.append(image)\n",
    "    \n",
    "\n",
    "    image_vert = np.array(tf.image.flip_up_down(image))\n",
    "    images.append(image_vert)\n",
    "\n",
    "    image_hor = np.array(tf.image.flip_left_right(image))\n",
    "    images.append(image_hor)\n",
    "\n",
    "    image_inv = np.array(tf.image.flip_left_right(image_vert))\n",
    "    images.append(image_inv)\n",
    "\n",
    "    imageb = cv2.resize(imageb, (size_,size_))\n",
    "    imageb = np.array(imageb, dtype = float)\n",
    "    imageb = np.expand_dims(imageb, 2)\n",
    "    imageb = imageb / 255.0\n",
    "    images.append(imageb)\n",
    "\n",
    "    imageb_vert = np.array(tf.image.flip_up_down(imageb))\n",
    "    images.append(imageb_vert)\n",
    "\n",
    "    imageb_hor = np.array(tf.image.flip_left_right(imageb))\n",
    "    images.append(imageb_hor)\n",
    "\n",
    "    imageb_inv = np.array(tf.image.flip_left_right(imageb_vert))\n",
    "    images.append(imageb_inv)\n",
    "\n",
    "    m22r = float(re.sub(\"_m33_.*\",\"\",re.sub(\"FeCrCo_m22_\",\"\",image_path[:-4])))\n",
    "    m33r = float(re.sub(\"_m23_.*\",\"\",re.sub(\"FeCrCo_m22_.*_m33_\",\"\",image_path[:-4])))\n",
    "    m23r = float(re.sub(\"_k_.*\",\"\",re.sub(\"FeCrCo_m22_.*_m33_.*_m23_\",\"\",image_path[:-4])))\n",
    "    kr = float(re.sub(\"_c.*\",\"\",re.sub(\"FeCrCo_m22_.*_m33_.*_m23_.*_k_\",\"\",image_path[:-4])))\n",
    "\n",
    "    m22 = float('%.5e'%m22r)\n",
    "    m33 = float('%.5e'%m33r)\n",
    "    m23 = float('%.5e'%m23r)\n",
    "    k = float('%.5e'%kr)\n",
    "\n",
    "    m22_list.append(m22)\n",
    "    k_list.append(k)\n",
    "\n",
    "data[\"m22\"] = np.array(m22_list, dtype = float)\n",
    "data[\"k\"] = np.array(k_list, dtype = float)\n",
    "    \n",
    "images = np.array(images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into 0.7/0.3 training/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Splitting data...\")\n",
    "data2 = pd.DataFrame(np.repeat(data.values, 8, axis = 0))\n",
    "data2.columns = data.columns\n",
    "trainX, testX, trainX_images, testX_images = train_test_split(data2, images, test_size = 0.3, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saves unprocessed training and test data to CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.to_csv(os.path.join(output,\"trainX.csv\"), index = False)\n",
    "testX.to_csv(os.path.join(output,\"testX.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescale the training and test M22 and Kappa values to be between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxY = trainX[[\"m22\", \"k\"]].max()\n",
    "trainY = np.array(trainX[[\"m22\", \"k\"]] / maxY, dtype = float)\n",
    "testY = np.array(testX[[\"m22\", \"k\"]] / maxY, dtype = float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescale the Fe min and max data to be between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vars = [\"min\", \"max\"]\n",
    "# mms = MinMaxScaler()\n",
    "\n",
    "# trainX = np.array(mms.fit_transform(trainX[vars]), dtype = float)\n",
    "# testX = np.array(mms.transform(testX[vars]), dtype = float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creates the multi-layered perceptron which accepts Fe min/max data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp = Sequential([\n",
    "#     Dense(8, input_dim = trainX.shape[1], activation = \"relu\"),\n",
    "#     Dense(4, activation = \"relu\")\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish(x, beta = 1):\n",
    "    return (x * sigmoid(beta * x))\n",
    "get_custom_objects().update({'swish': Activation(swish)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creates the CNN which accepts the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = (f1_, f2_, f3_)\n",
    "\n",
    "input_shape = (size_,size_,1)\n",
    "input = Input(shape = input_shape)\n",
    "\n",
    "for i, size in enumerate(filters):\n",
    "    if i == 0:\n",
    "            x = input\n",
    "\n",
    "    x = Conv2D(size, (3,3), padding = \"same\", activation = \"relu\")(x)\n",
    "    x = BatchNormalization(axis = -1)(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation = \"relu\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(64, activation = \"relu\")(x)\n",
    "\n",
    "cnn = Model(input, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = lr_\n",
    "epochs = ep_\n",
    "batch_size = bs_\n",
    "decay = dc_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combines the MLP and CNN into one network and compiles the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_input = concatenate([mlp.output, cnn.output])\n",
    "x = Dense(16, activation = \"relu\")(cnn.output)\n",
    "x = Dense(8, activation = \"relu\")(x)\n",
    "x = Dense(2, activation = \"linear\")(x)\n",
    "model = Model(inputs = cnn.input, outputs = x)\n",
    "opt = Adam(learning_rate = learning_rate, decay = decay)\n",
    "model.compile(loss = \"mean_absolute_percentage_error\", optimizer = opt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trains the model on the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training model...\")\n",
    "# es = EarlyStopping(monitor = \"val_loss\", min_delta = 0.1, patience = 100, verbose = 1, mode = \"min\", baseline = 4.0)\n",
    "result = model.fit(\n",
    "    x = trainX_images,\n",
    "    y = trainY,\n",
    "    validation_data = (testX_images, testY),\n",
    "    epochs = epochs,\n",
    "    batch_size = batch_size,\n",
    "    verbose = 2\n",
    "    # callbacks = [es]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Makes predictions based on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Making predictions...\")\n",
    "predictions = model.predict(testX_images, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saves the predictions for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m22_pred = predictions.transpose()[0]\n",
    "k_pred = predictions.transpose()[1]\n",
    "m22_act = np.array(testY).transpose()[0]\n",
    "k_act = np.array(testY).transpose()[1]\n",
    "\n",
    "compare_m22 = {\n",
    "    \"Actual\" : m22_act,\n",
    "    \"Predicted\" : m22_pred\n",
    "}\n",
    "\n",
    "compare_k = {\n",
    "    \"Actual\" : k_act,\n",
    "    \"Predicted\" : k_pred\n",
    "}\n",
    "\n",
    "data_m22 = pd.DataFrame(compare_m22)\n",
    "data_k = pd.DataFrame(compare_k)\n",
    "\n",
    "data_m22.to_csv(os.path.join(output,\"results_m22.csv\"), index = False)\n",
    "data_k.to_csv(os.path.join(output,\"results_k.csv\"), index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiles statistics into a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m22_perc_diff = (np.abs(m22_act - m22_pred)/m22_act)*100.0\n",
    "k_perc_diff = (np.abs(k_act - k_pred)/k_act)*100.0\n",
    "\n",
    "m22_mean = np.mean(m22_perc_diff)\n",
    "k_mean = np.mean(k_perc_diff)\n",
    "m22_stdev = np.std(m22_perc_diff)\n",
    "k_stdev = np.std(k_perc_diff)\n",
    "m22_r2 = r2_score(m22_act,m22_pred)\n",
    "k_r2 = r2_score(k_act,k_pred)\n",
    "m22_mse = mean_squared_error(m22_act,m22_pred)\n",
    "k_mse = mean_squared_error(k_act,k_pred)\n",
    "\n",
    "stats_dict = {\n",
    "    \"Parameter\":[\"m22\",\"k\"],\n",
    "    \"Mean Percent Difference\":[m22_mean,k_mean],\n",
    "    \"Standard Deviation of Percent Difference\":[m22_stdev,k_stdev],\n",
    "    \"R-Squared\":[m22_r2,k_r2],\n",
    "    \"Mean Squared Error\":[m22_mse,k_mse]\n",
    "}\n",
    "\n",
    "stats = pd.DataFrame(stats_dict)\n",
    "stats.to_csv(os.path.join(output,\"statistics.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saves the model and its data for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(output,\"saved_model\"))\n",
    "\n",
    "history = pd.DataFrame(result.history)\n",
    "history.to_csv(os.path.join(output,\"history.csv\"), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "22ac2367c98d02b85f0e0b019fc21e527d0ae92ae46904a857f875598d38762c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
